{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18793003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from typing import TypedDict , Annotated\n",
    "from langchain_core.messages import BaseMessage , HumanMessage,SystemMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ba931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "model = OllamaLLM(model=\"llama2\",temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9603ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    \n",
    "    message: Annotated[list[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7b883b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chat_node(state:ChatState):\n",
    "    \n",
    "    message= state['message']\n",
    "    response = model.invoke(message)\n",
    "    return {'message': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d0b494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = MemorySaver()\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "\n",
    "graph.add_node('chatNode',Chat_node)\n",
    "graph.add_edge(START,'chatNode')\n",
    "graph.add_edge('chatNode',END)\n",
    "\n",
    "chatbot = graph.compile(checkpointer=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ebed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(chatbot.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78090099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langgraph (short for language graph) is a computational model of human language that represents the structure of language as a network or graph. The model posits that the meaning of words and phrases is determined by their relationships to other words and phrases in the linguistic system, rather than by any inherent meaning they may have in isolation.\\n\\nIn a langgraph, words and phrases are represented as nodes, and the relationships between them are represented as edges or links. The edges may be labeled with various types of information, such as syntactic, semantic, or pragmatic relationships. For example, a sentence like \"The dog chased the cat\" might be represented as a langgraph with the words \"dog,\" \"chased,\" and \"cat\" as nodes, and the relationship \"agent-action-patient\" labeled on the edge connecting them.\\n\\nLanggraphs can be used to represent a wide range of linguistic phenomena, including grammatical structures, lexical semantics, and pragmatic effects. They have been applied in various fields such as natural language processing, computational linguistics, cognitive science, and artificial intelligence.\\n\\nOne of the key insights of langgraphs is that the meaning of a sentence or utterance can be determined by the network of relationships between its constituent parts, rather than just by the individual words or phrases themselves. This perspective has important implications for understanding how language works and how it is processed in the mind.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {'message':[HumanMessage(content=\"what is langgraph?\")]}\n",
    "\n",
    "chatbot.invoke(initial_state)['message'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1d99502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: hi my name aditya\n",
      "AI: Assistant: Hello Aditya! It's nice to meet you. How can I assist you today? Is there something you would like to talk about or ask?\n",
      "AI: Assistant: Hello Aditya! It's nice to meet you. How can I assist you today? Is there something you would like to talk about or ask?\n",
      "user: what is my name?\n",
      "user: what is my name?\n",
      "AI: Assistant: Hello Aditya! It's great to meet you too. By the way, your name is... *pauses* Aditya! ðŸ˜Š Is there anything else on your mind that you would like to talk about or ask? I'm here to listen and help in any way I can.\n",
      "AI: Assistant: Hello Aditya! It's great to meet you too. By the way, your name is... *pauses* Aditya! ðŸ˜Š Is there anything else on your mind that you would like to talk about or ask? I'm here to listen and help in any way I can.\n",
      "user: quit\n",
      "user: quit\n"
     ]
    }
   ],
   "source": [
    "thread_id = '1'\n",
    "\n",
    "while True:\n",
    "    ques = input(\"Ask anything: \")\n",
    "    print('user:', ques)\n",
    "    if ques.strip().lower() in ['quit','exit','bye']:\n",
    "        break\n",
    "    config = {'configurable':{'thread_id':thread_id}}\n",
    "    res = chatbot.invoke({'message':[HumanMessage(content=ques)]},config=config)\n",
    "    print('AI:', res['message'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d56c017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'message': [HumanMessage(content='hi my name aditya', additional_kwargs={}, response_metadata={}, id='6de8222a-acae-48ba-b63e-f1ee85e4fc41'), HumanMessage(content=\"Assistant: Hello Aditya! It's nice to meet you. How can I assist you today? Is there something you would like to talk about or ask?\", additional_kwargs={}, response_metadata={}, id='1e6527d0-b741-4532-8209-1243808d7914'), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}, id='cc694ba7-eb87-41d4-96b1-d8296e4d2aef'), HumanMessage(content=\"Assistant: Hello Aditya! It's great to meet you too. By the way, your name is... *pauses* Aditya! ðŸ˜Š Is there anything else on your mind that you would like to talk about or ask? I'm here to listen and help in any way I can.\", additional_kwargs={}, response_metadata={}, id='bda98fd4-f712-44f6-810b-9a604d07908f')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0d33aa-77a8-67d3-8004-b019a650b6a8'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-12-07T07:02:11.987451+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0d33aa-1de5-62a8-8003-a67566f95148'}}, tasks=(), interrupts=())\n"
     ]
    }
   ],
   "source": [
    "state = chatbot.get_state(config=config)\n",
    "print(state)\n",
    "# for i in state.values['message']:\n",
    "#     print(i.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600fd08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
